#!/usr/bin/env python3
"""
News URL Scraper - Main Module
"""

import argparse
import os
import sys
from typing import Optional

from src.scraper import NewsLinkScraper
from src.url_updater import URLUpdater


def scrape_command(args: Optional[argparse.Namespace] = None) -> None:
    """Execute the scraping command."""
    input_file = "data/input/all-govbr-sites.csv"
    output_file = "data/stage/scraped_urls.csv"

    os.makedirs("data/stage", exist_ok=True)

    if not os.path.exists(input_file):
        print(f"âŒ Arquivo de entrada nÃ£o encontrado: {input_file}")
        sys.exit(1)

    print("ğŸš€ Iniciando raspagem de URLs de notÃ­cias...")
    print(f"ğŸ“‚ Entrada: {input_file}")
    print(f"ğŸ“‚ SaÃ­da: {output_file}")
    print()

    scraper = NewsLinkScraper()

    try:
        total_sites, sites_with_news = scraper.scrape_from_csv(input_file, output_file)
        success_rate = (sites_with_news / total_sites) * 100

        print()
        print("âœ… Raspagem concluÃ­da!")
        print(f"ğŸ“Š {sites_with_news}/{total_sites} sites com links de notÃ­cias")
        print(f"ğŸ“ˆ Taxa de sucesso: {success_rate:.1f}%")
        print(f"ğŸ’¾ Resultados salvos em: {output_file}")

    except Exception as e:
        print(f"âŒ Erro durante a raspagem: {e}")
        sys.exit(1)


def update_urls_command(args: Optional[argparse.Namespace] = None) -> None:
    """Execute the URL update command."""
    csv_file = "data/stage/scraped_urls.csv"
    yaml_input = "data/input/site_urls.yaml"
    yaml_output = "data/output/site_urls.yaml"

    os.makedirs("data/output", exist_ok=True)

    if not os.path.exists(csv_file):
        print(f"âŒ Arquivo de resultados nÃ£o encontrado: {csv_file}")
        print("ğŸ’¡ Execute primeiro: python main.py scrape")
        sys.exit(1)

    if not os.path.exists(yaml_input):
        print(f"âŒ Arquivo YAML de entrada nÃ£o encontrado: {yaml_input}")
        sys.exit(1)

    print("ğŸ”„ Iniciando atualizaÃ§Ã£o de URLs...")
    print(f"ğŸ“‚ CSV de entrada: {csv_file}")
    print(f"ï¿½ï¿½ YAML de entrada: {yaml_input}")
    print(f"ğŸ“‚ YAML de saÃ­da: {yaml_output}")
    print()

    updater = URLUpdater()

    try:
        total_agencies, discrepancies = updater.update_urls_from_csv(
            csv_file, yaml_input, yaml_output
        )

        accuracy_rate = ((total_agencies - discrepancies) / total_agencies) * 100

        print()
        print("âœ… AtualizaÃ§Ã£o concluÃ­da!")
        print(f"ğŸ“Š {total_agencies - discrepancies}/{total_agencies} URLs corretos")
        print(f"ğŸ“ˆ Taxa de acerto: {accuracy_rate:.1f}%")
        print(f"ğŸ’¾ YAML atualizado salvo em: {yaml_output}")

    except Exception as e:
        print(f"âŒ Erro durante a atualizaÃ§Ã£o: {e}")
        sys.exit(1)


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="News URL Scraper for Brazilian Government Websites",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
    python main.py scrape        # Raspar URLs de notÃ­cias
    python main.py update_urls   # Atualizar arquivo de configuraÃ§Ã£o
        """
    )

    subparsers = parser.add_subparsers(
        dest='command',
        help='Comandos disponÃ­veis',
        title='Comandos'
    )

    scrape_parser = subparsers.add_parser(
        'scrape',
        help='Raspar URLs de notÃ­cias dos sites governamentais'
    )

    update_parser = subparsers.add_parser(
        'update_urls',
        help='Atualizar arquivo site_urls.yaml baseado nos resultados'
    )

    args = parser.parse_args()

    if args.command == 'scrape':
        scrape_command(args)
    elif args.command == 'update_urls':
        update_urls_command(args)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
